# # -*- coding: utf-8 -*-
# """SER_with_SUBESCOO_dataset.ipynb

# Automatically generated by Colaboratory.

# Original file is located at
#     https://colab.research.google.com/drive/1ofZKsjLgdeItZXPAPgexSMZdZbuRuB3Z

# # Loading Dataset
# """

# import soundfile
# import librosa
# import numpy as np
# from IPython.display import Audio

# from sklearn.model_selection import train_test_split
# from sklearn.neural_network import MLPClassifier
# from sklearn.metrics import accuracy_score, f1_score

# """Mounting google drive"""

# from google.colab import drive
# drive.mount('/content/drive')

# import os

# paths = []
# labels = []

# for dirpath, dirname, filenames in os.walk('/content/drive/MyDrive/SUBESCO'):
#   # print("Dirpath: ", dirpath)
#   # print('Dirname: ', dirname)
#   # print('Filename: ', filenames)
#   #print(len(filename))
#   for filename in filenames:
#     paths.append(os.path.join(dirpath, filename))
#     # print(os.path.join(dirpath, filename))
#     label = filename.split('_')
#     # print(filename)
#     # print(label)

#     label = label[-2]
#     # print(label.lower())
#     labels.append(label.lower())

# print("Dataset loaded.")

# print(paths)
# print(labels)

# paths[:10]

# print(labels[:10])

# """# Creating DataFrame"""

# import pandas as pd

# df = pd.DataFrame()
# df['speech'] = paths
# df['label'] = labels

# df

# df['label'].value_counts()

# """# Visualization of audio"""

# Audio(paths[0])

# print(df['speech'][0])

# Audio(df['speech'][0])

# """# Exploratory Data Analysis"""

# import seaborn as sns

# sns.countplot(df['label'])

# """# Feature Extraction (slow process)"""



# # for i in range(len(df)):
# #   print(df['speech'])

# # print(df.apply(lambda row: row['speech']), axis=1)

# # for index, row in df.iterrows():
# #   print(row['speech'], row['label'])

# # def extract_feature(file_name, mfcc, chroma, mel):
# #   with soundfile.SoundFile(file_name) as sound_file:
# #     X = sound_file.read(dtype='float32')
# #     sample_rate = sound_file.samplerate

# #     if chroma:
# #       stft = np.abs(librosa.stft(X))

# #     result = np.array([])
# #     if mfcc:
# #       mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)
# #       result = np.hstack((result, mfccs))

# #     if chroma:
# #       chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)
# #       result = np.hstack((result, chroma))

# #     if mel:
# #       mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)
# #       result = np.hstack((result, mel))

# #     return result

# """Note: 
# Extracted features are:
#   1. Mel-Frequency Cepstrum Coefficients (MFCC)
#   2. Chroma
#   3. Melspectrogram

# # TODO:
# Apply other feature extraction technique.
# """

# def extract_feature(file_name, mfcc, chroma, mel):
#   # with soundfile.SoundFile(file_name) as sound_file:
#   # X = sound_file.read(dtype='float32')
#   # sample_rate = sound_file.samplerate
#   X, sample_rate = librosa.load(file_name)

#   # print(X, sample_rate)

#   if chroma:
#     stft = np.abs(librosa.stft(X))

#   result = np.array([])
#   if mfcc:
#     mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)
#     result = np.hstack((result, mfccs))

#   if chroma:
#     chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)
#     result = np.hstack((result, chroma))

#   if mel:
#     mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)
#     result = np.hstack((result, mel))

#   return result

# # x = extract_feature(df['speech'][0], mfcc=True, chroma=True, mel=True) # extract feature is working correctly

# """# Allowed emotions"""

# # emotions = ['happy']

# # emotions

# """Extract feature"""

# X, y = [], []

# for index, row in df.iterrows():
#   emotion = row['label']

#   # if emotion in emotions:
#   X.append(extract_feature(row['speech'], mfcc=True, chroma=True, mel=True))
#   y.append(row['label'])
  
#   # print(type(row['speech']))
#   #print(row['speech'])
#   #print(row['label'])

# print(y)

# """# Splitting dataset"""

# X_train, X_test, y_train, y_test = train_test_split(np.array(X), y, test_size=0.25, random_state=9)

# X_train

# X_test

# y_train

# print(type(y_test))

# y_test



# type(X_train)

# # Get shape of training and testing datasets

# print((X_train.shape[0], X_test.shape[0]))

# # Get the number of features extracted

# print(f'Features extracted: {X_train.shape[1]}')

# """# Classifier"""

# # Initialize the Multi-layer Perceptron Classifier

# model = MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)

# model.fit(X_train, y_train)

# """# Predict the test set"""

# y_predict = model.predict(X_test)

# #y_predict

# y_predict

# """# Accuracy of the model"""

# accuracy = accuracy_score(y_true=y_test, y_pred=y_predict)

# print("Accuracy: {:.2f}%".format(accuracy*100))

# f1_score(y_test, y_predict, average=None)

# import pandas as pd

# df = pd.DataFrame({'Actual': y_test, 'Predicted': y_predict})
# df.head(20)

# """# Saving the model"""

# # import pickle

# # with open('modelForPrediction.sav', 'wb')
# import pickle
# # Writing different model files to file
# with open( 'modelForPrediction1.sav', 'wb') as f:
#     pickle.dump(model,f)

# import pickle

# filename = 'modelForPrediction1.sav'
# loaded_model = pickle.load(open(filename, 'rb')) # loading the model file from the storage

# feature=extract_feature("/content/drive/MyDrive/SUBESCO/F_01_OISHI_S_10_ANGRY_1.wav", mfcc=True, chroma=True, mel=True)

# feature=feature.reshape(1,-1)

# prediction=loaded_model.predict(feature)
# prediction

